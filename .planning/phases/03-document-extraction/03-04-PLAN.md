---
phase: 03-document-extraction
plan: 04
type: execute
wave: 2
depends_on: ["03-01", "03-02"]
files_modified:
  - agents/parser.ts
  - inngest/functions/analyze-nda.ts
  - agents/validation/gates.ts
autonomous: true

must_haves:
  truths:
    - "Parser agent uses new extractDocument for file uploads"
    - "Word Add-in content skips extraction, gets structure detection"
    - "Extraction errors (encrypted, corrupt) become NonRetriableError in pipeline"
    - "OCR-required documents emit specific error for Phase 4 routing"
    - "Structure detection runs on all documents"
  artifacts:
    - path: "agents/parser.ts"
      provides: "Parser with extraction and structure detection"
      exports: ["runParserAgent"]
    - path: "agents/validation/gates.ts"
      provides: "Extraction validation gate"
      exports: ["validateExtractionResult"]
  key_links:
    - from: "agents/parser.ts"
      to: "lib/document-extraction"
      via: "import"
      pattern: "from '@/lib/document-extraction'"
    - from: "inngest/functions/analyze-nda.ts"
      to: "agents/parser.ts"
      via: "runParserAgent call"
      pattern: "runParserAgent\\("
---

<objective>
Integrate new extraction infrastructure into the analysis pipeline.

Purpose: Update parser agent to use new extractors with quality metrics and structure detection. Add extraction validation gate. Wire into Inngest pipeline with proper error handling.

Output:
- Updated parser agent with structure detection
- Extraction validation gate for pipeline
- Pipeline integration with error mapping
</objective>

<execution_context>
@/Users/medelman/.claude/get-shit-done/workflows/execute-plan.md
@/Users/medelman/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-document-extraction/03-RESEARCH.md
@.planning/phases/03-document-extraction/03-01-PLAN.md
@.planning/phases/03-document-extraction/03-02-PLAN.md

# Existing code
@agents/parser.ts
@agents/validation/gates.ts
@inngest/functions/analyze-nda.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add extraction validation gate</name>
  <files>agents/validation/gates.ts</files>
  <action>
Add extraction validation to agents/validation/gates.ts:

After the existing validateTokenBudget function, add:

```typescript
// ============================================================================
// Extraction Validation
// ============================================================================

import type { ExtractionResult } from '@/lib/document-extraction'
import { OcrRequiredError, EncryptedDocumentError, CorruptDocumentError } from '@/lib/errors'

/**
 * Result of extraction validation.
 */
export interface ExtractionValidation {
  /** Whether extraction passed validation */
  valid: boolean
  /** Error details if validation failed */
  error?: {
    code: 'EXTRACTION_FAILED' | 'OCR_REQUIRED' | 'ENCRYPTED' | 'CORRUPT' | 'NON_ENGLISH'
    message: string
    userFacing: string
  }
  /** Warnings that don't block processing */
  warnings: string[]
}

/**
 * Validates extraction result before proceeding to chunking.
 *
 * Checks for:
 * - OCR requirement (routes to Phase 4)
 * - Encryption (user action required)
 * - Corruption (user action required)
 * - Quality issues (warnings only)
 *
 * @param result - Extraction result from extractDocument
 * @returns Validation result with error details
 */
export function validateExtractionResult(
  result: ExtractionResult
): ExtractionValidation {
  const warnings: string[] = result.quality.warnings.map(w => w.message)

  // OCR requirement is a soft failure - document can be routed to OCR phase
  if (result.quality.requiresOcr) {
    return {
      valid: false,
      error: {
        code: 'OCR_REQUIRED',
        message: 'Document requires OCR processing',
        userFacing: 'Document requires OCR processing (may take longer)',
      },
      warnings,
    }
  }

  // Low confidence is a warning, not a failure
  if (result.quality.confidence < 0.3) {
    warnings.push(`Low extraction confidence: ${(result.quality.confidence * 100).toFixed(0)}%`)
  }

  return { valid: true, warnings }
}

/**
 * Maps extraction errors to pipeline-appropriate errors.
 *
 * Returns { retriable: false } for user-fixable errors (encrypted, corrupt)
 * and { retriable: false, routeToOcr: true } for OCR-required documents.
 */
export function mapExtractionError(
  error: unknown
): { retriable: boolean; routeToOcr?: boolean; userMessage: string } {
  if (error instanceof EncryptedDocumentError) {
    return {
      retriable: false,
      userMessage: 'Document is password-protected. Please upload an unprotected version.',
    }
  }

  if (error instanceof CorruptDocumentError) {
    return {
      retriable: false,
      userMessage: 'Could not process this file. Try re-uploading or use a different format.',
    }
  }

  if (error instanceof OcrRequiredError) {
    return {
      retriable: false,
      routeToOcr: true,
      userMessage: 'Document requires OCR processing (may take longer)',
    }
  }

  // Unknown error - don't retry, show generic message
  return {
    retriable: false,
    userMessage: 'Failed to extract text from document. Please try a different file.',
  }
}
```

Also update the imports at the top of the file to include the new error types:
```typescript
import { OcrRequiredError, EncryptedDocumentError, CorruptDocumentError } from '@/lib/errors'
```
  </action>
  <verify>
TypeScript compiles: `pnpm tsc --noEmit 2>&1 | head -20`
Functions exist: `grep -E "validateExtractionResult|mapExtractionError" agents/validation/gates.ts`
  </verify>
  <done>Extraction validation gate and error mapper added</done>
</task>

<task type="auto">
  <name>Task 2: Update parser agent with new extraction and structure detection</name>
  <files>agents/parser.ts</files>
  <action>
Update agents/parser.ts to use new extraction infrastructure:

1. Update imports:
```typescript
import {
  extractDocument,
  detectStructure,
  type ExtractionResult as FullExtractionResult,
  type DocumentStructure,
} from '@/lib/document-extraction'
import { chunkDocument, type DocumentChunk } from '@/lib/document-processing'
```

2. Update ParserOutput interface to include structure:
```typescript
export interface ParserOutput {
  document: {
    documentId: string
    title: string
    rawText: string
    chunks: ParsedChunk[]
    structure: DocumentStructure
  }
  tokenUsage: {
    embeddingTokens: number
  }
  quality: {
    charCount: number
    wordCount: number
    pageCount: number
    confidence: number
    warnings: string[]
  }
}
```

3. Update runParserAgent to use new extractors:

For web/web-upload sources:
```typescript
if (source === 'web' || source === 'web-upload') {
  // Fetch document from database to get blob URL
  const doc = await db.query.documents.findFirst({
    where: eq(documents.id, documentId),
  })

  if (!doc?.fileUrl) {
    throw new NotFoundError(`Document ${documentId} not found or has no file URL`)
  }

  // Download from Vercel Blob URL
  const response = await fetch(doc.fileUrl)
  if (!response.ok) {
    throw new InternalError(`Failed to download document: ${response.statusText}`)
  }
  const arrayBuffer = await response.arrayBuffer()
  const buffer = Buffer.from(arrayBuffer)
  const contentType = response.headers.get('content-type') ?? 'application/pdf'

  // Use new extraction with validation
  const extraction = await extractDocument(buffer, contentType, {
    fileSize: doc.fileSize ?? undefined,
  })

  rawText = extraction.text
  title = doc.title ?? extraction.metadata.title ?? 'Untitled'
  structure = await detectStructure(rawText)
  quality = {
    charCount: extraction.quality.charCount,
    wordCount: extraction.quality.wordCount,
    pageCount: extraction.pageCount,
    confidence: extraction.quality.confidence,
    warnings: extraction.quality.warnings.map(w => w.message),
  }
}
```

For word-addin source:
```typescript
else {
  // Word Add-in: use provided content
  if (!content) {
    throw new ValidationError('Word Add-in source requires content')
  }
  rawText = content.rawText.normalize('NFC')
  title = metadata?.title ?? 'Untitled'

  // Still run structure detection on Word Add-in content
  structure = await detectStructure(rawText)
  quality = {
    charCount: rawText.length,
    wordCount: rawText.split(/\s+/).filter(Boolean).length,
    pageCount: 1,
    confidence: 1.0, // Word provides clean text
    warnings: [],
  }
}
```

4. Include structure and quality in return:
```typescript
return {
  document: {
    documentId,
    title,
    rawText,
    chunks,
    structure,
  },
  tokenUsage: {
    embeddingTokens: embeddingResult.totalTokens,
  },
  quality,
}
```
  </action>
  <verify>
TypeScript compiles: `pnpm tsc --noEmit 2>&1 | head -20`
Uses new extraction: `grep "extractDocument" agents/parser.ts`
Has structure: `grep "detectStructure" agents/parser.ts`
  </verify>
  <done>Parser agent uses new extraction and structure detection</done>
</task>

<task type="auto">
  <name>Task 3: Update pipeline with extraction error handling</name>
  <files>inngest/functions/analyze-nda.ts</files>
  <action>
Update inngest/functions/analyze-nda.ts to handle extraction errors properly:

1. Add import for error mapping:
```typescript
import { mapExtractionError } from '@/agents/validation/gates'
import {
  EncryptedDocumentError,
  CorruptDocumentError,
  OcrRequiredError,
} from '@/lib/errors'
```

2. Update the parser step to handle extraction errors:

Wrap the existing `step.run("parse-document", ...)` with error handling:

```typescript
// Parse document with extraction error handling
let parserResult: ParserOutput
try {
  parserResult = await step.run("parse-document", async () => {
    return await runParserAgent({
      documentId,
      tenantId,
      source,
      content,
      metadata,
    })
  })
} catch (error) {
  // Map extraction errors to appropriate pipeline errors
  if (
    error instanceof EncryptedDocumentError ||
    error instanceof CorruptDocumentError ||
    error instanceof OcrRequiredError
  ) {
    const mapped = mapExtractionError(error)

    // Persist failure state
    await step.run("persist-extraction-failure", async () => {
      await db
        .update(analyses)
        .set({
          status: mapped.routeToOcr ? "pending_ocr" : "failed",
          errorMessage: mapped.userMessage,
          metadata: {
            failedAt: "extraction",
            errorCode: error instanceof OcrRequiredError ? "OCR_REQUIRED" :
                       error instanceof EncryptedDocumentError ? "ENCRYPTED" : "CORRUPT",
          },
        })
        .where(eq(analyses.id, analysisId))
    })

    throw new NonRetriableError(mapped.userMessage)
  }
  throw error
}
```

Note: The existing validation gates and budget checks remain unchanged after this block. This only adds extraction-specific error handling before those gates run.
  </action>
  <verify>
TypeScript compiles: `pnpm tsc --noEmit 2>&1 | head -20`
Has error handling: `grep "mapExtractionError" inngest/functions/analyze-nda.ts`
Has new status: `grep "pending_ocr" inngest/functions/analyze-nda.ts`
  </verify>
  <done>Pipeline handles extraction errors with proper failure states</done>
</task>

</tasks>

<verification>
1. TypeScript compiles without errors
2. Parser agent returns structure with sections
3. Extraction validation gate checks quality
4. Pipeline maps errors to NonRetriableError
5. Failed extractions persist with appropriate status
6. OCR-required documents get "pending_ocr" status
7. Tests pass: `pnpm test -- agents/parser inngest/functions/analyze-nda`
</verification>

<success_criteria>
- Parser uses extractDocument for web uploads
- Parser runs detectStructure on all content
- ParserOutput includes structure and quality
- Pipeline catches extraction errors
- Encrypted/corrupt -> failed status
- OCR-required -> pending_ocr status
- Word Add-in content gets structure detection
</success_criteria>

<output>
After completion, create `.planning/phases/03-document-extraction/03-04-SUMMARY.md`
</output>
