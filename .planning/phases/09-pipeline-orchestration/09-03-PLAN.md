---
phase: 09-pipeline-orchestration
plan: 03
type: execute
wave: 2
depends_on: ["09-01"]
files_modified:
  - inngest/functions/analyze-nda.ts
autonomous: true

must_haves:
  truths:
    - "Classifier runs as per-batch Inngest steps, not a single monolithic step"
    - "Risk scorer runs as per-batch Inngest steps, not a single monolithic step"
    - "Chunk-level progress visible: 'Classifying clause 7 of 15...'"
    - "Each batch is independently retriable on failure"
    - "Rate limit delays between batches for Claude and Voyage AI"
  artifacts:
    - path: "inngest/functions/analyze-nda.ts"
      provides: "Per-batch classifier and risk scorer steps with chunk-level progress"
      contains: "classify-batch-"
  key_links:
    - from: "inngest/functions/analyze-nda.ts"
      to: "agents/classifier.ts"
      via: "Per-batch calls to classifier with subset of chunks"
      pattern: "classify-batch"
    - from: "inngest/functions/analyze-nda.ts"
      to: "agents/risk-scorer.ts"
      via: "Per-batch calls to risk scorer with subset of clauses"
      pattern: "score-batch"
---

<objective>
Split classifier and risk scorer into per-batch Inngest steps for chunk-level progress and independent retry.

Purpose: Currently classifier and risk scorer run as single monolithic step.run() calls. This prevents showing "Scoring clause 7 of 15..." progress and means a failure 90% through the step loses all work. Splitting into per-batch steps gives granular progress updates and makes each batch independently retriable.
Output: analyze-nda.ts with per-batch classifier steps, per-batch risk scorer steps, and chunk-level progress emissions between batches.
</objective>

<execution_context>
@/Users/medelman/.claude/get-shit-done/workflows/execute-plan.md
@/Users/medelman/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-pipeline-orchestration/09-RESEARCH.md
@.planning/phases/09-pipeline-orchestration/09-01-PLAN.md
@inngest/functions/analyze-nda.ts
@agents/classifier.ts
@agents/risk-scorer.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Split classifier into per-batch Inngest steps</name>
  <files>inngest/functions/analyze-nda.ts</files>
  <action>
  The classifier agent currently processes all chunks internally in batches (CLASSIFIER_BATCH_SIZE = 4), but the entire operation runs in a single `step.run('classifier-agent', ...)`. This needs to be refactored so each batch is a separate Inngest step.

  **Approach:** Instead of calling `runClassifierAgent()` which handles batching internally, we need to call the classifier's per-batch processing directly. However, since `runClassifierAgent` does its own batching logic with RAG retrieval and neighbor context, the cleanest approach is to:

  1. Keep `runClassifierAgent` as-is (it returns `clauses` and `rawClassifications`)
  2. BUT wrap it in a way that its internal batches become separate Inngest steps

  The simplest and most practical approach: Since `runClassifierAgent` already processes batches of 4 chunks internally, and a typical NDA has 15-30 chunks, the entire classifier call takes maybe 15-45 seconds. Rather than refactoring the agent internals, we can:

  a) Keep the single `classifier-agent` step for the actual LLM work
  b) Add progress emissions AROUND it with estimated sub-progress

  Actually, re-reading the CONTEXT.md decisions: "Chunk-level progress visible in long stages (Scoring clause 7 of 15...)" is a requirement. To deliver real chunk-level progress, we need to pass the step function into the agent or split at the Inngest level.

  **Better approach: Create a `runClassifierBatch` wrapper function** that processes a single batch of chunks. Then in the pipeline, iterate batches at the Inngest step level:

  Import the necessary internals from the classifier module. If `runClassifierAgent` isn't batch-splittable (it handles RAG retrieval, neighbor context, etc.), create a new exported function `classifyChunkBatch` in `agents/classifier.ts` that processes a single batch.

  However, per the plan constraints (2-3 files max and focused scope), the pragmatic approach is:

  **In analyze-nda.ts, refactor the classifier section in BOTH analyzeNda and analyzeNdaAfterOcr:**

  Replace the single `step.run('classifier-agent', ...)` with a batched loop:

  ```typescript
  // Step 8: Classifier Agent (per-batch for chunk-level progress)
  const CLASSIFIER_BATCH_SIZE = 4 // Match classifier internal batch size
  const classifierChunks = classifierDocument.chunks
  const totalClassifierBatches = Math.ceil(classifierChunks.length / CLASSIFIER_BATCH_SIZE)

  let allClassifications: typeof classifierResult.rawClassifications = []
  let allClauses: typeof classifierResult.clauses = []

  for (let batch = 0; batch < totalClassifierBatches; batch++) {
    const batchStart = batch * CLASSIFIER_BATCH_SIZE
    const batchEnd = Math.min(batchStart + CLASSIFIER_BATCH_SIZE, classifierChunks.length)
    const batchChunks = classifierChunks.slice(batchStart, batchEnd)

    // Create a sub-document for this batch
    const batchDocument = {
      ...classifierDocument,
      chunks: batchChunks,
    }

    const batchResult = await step.run(`classify-batch-${batch}`, () =>
      runClassifierAgent({
        parsedDocument: batchDocument,
        budgetTracker,
      })
    )

    allClassifications.push(...batchResult.rawClassifications)
    allClauses.push(...batchResult.clauses)

    // Chunk-level progress
    const processed = Math.min(batchEnd, classifierChunks.length)
    await emitProgress(
      'classifying',
      40 + Math.round((processed / classifierChunks.length) * 20), // 40-60% range
      `Classifying clause ${processed} of ${classifierChunks.length}...`
    )

    // Rate limit between batches (Claude 60 RPM)
    if (batch < totalClassifierBatches - 1) {
      await step.sleep(`rate-limit-classify-${batch}`, getRateLimitDelay('claude'))
    }
  }

  // Reassemble the combined result for downstream use
  const classifierResult = {
    clauses: allClauses,
    rawClassifications: allClassifications,
  }
  ```

  **Important type considerations:**
  - `runClassifierAgent` returns `{ clauses, rawClassifications }`. When processing batches, chunk indices in `rawClassifications` are relative to the batch's `parsedDocument.chunks`, but `chunkIndex` in rawClassifications corresponds to the global `chunk.index` property which is preserved since we're slicing the original chunks array.
  - The classifier uses neighbor context (chunks before/after) -- by passing the full document but only a slice of chunks, the classifier still has access to neighbor text via the rawText. However, it may lose the neighbor context optimization. This is acceptable for now since the main purpose is progress granularity and retriability.

  Remove the old single-step classifier call and its emitProgress call that came after.

  Apply the same refactoring to the `analyzeNdaAfterOcr` function.
  </action>
  <verify>Run `pnpm lint`. Grep for `classify-batch-` to confirm per-batch step IDs exist. Verify no remaining `step.run('classifier-agent'` (old monolithic step).</verify>
  <done>Classifier runs as per-batch Inngest steps with chunk-level progress messages like "Classifying clause 7 of 15...", each batch independently retriable, rate limits between batches.</done>
</task>

<task type="auto">
  <name>Task 2: Split risk scorer into per-batch Inngest steps</name>
  <files>inngest/functions/analyze-nda.ts</files>
  <action>
  Apply the same per-batch pattern to the risk scorer in both `analyzeNda` and `analyzeNdaAfterOcr`.

  The risk scorer processes individual clauses (not chunks). After classification, we have `classifierResult.clauses` -- typically 5-15 clauses. Score them in batches of 3-5:

  ```typescript
  // Step 9: Risk Scorer Agent (per-batch for clause-level progress)
  const SCORER_BATCH_SIZE = 3
  const clausesToScore = classifierResult.clauses
  const totalScorerBatches = Math.ceil(clausesToScore.length / SCORER_BATCH_SIZE)

  let allAssessments: typeof riskResult.assessments = []
  let lastRiskResult: typeof riskResult | null = null

  for (let batch = 0; batch < totalScorerBatches; batch++) {
    const batchStart = batch * SCORER_BATCH_SIZE
    const batchEnd = Math.min(batchStart + SCORER_BATCH_SIZE, clausesToScore.length)
    const batchClauses = clausesToScore.slice(batchStart, batchEnd)

    const batchResult = await step.run(`score-batch-${batch}`, () =>
      runRiskScorerAgent({
        clauses: batchClauses,
        budgetTracker,
        perspective: 'balanced',
      })
    )

    allAssessments.push(...batchResult.assessments)
    lastRiskResult = batchResult

    // Clause-level progress
    const scored = Math.min(batchEnd, clausesToScore.length)
    await emitProgress(
      'scoring',
      60 + Math.round((scored / clausesToScore.length) * 20), // 60-80% range
      `Scoring clause ${scored} of ${clausesToScore.length}...`
    )

    // Rate limit between batches (Claude 60 RPM)
    if (batch < totalScorerBatches - 1) {
      await step.sleep(`rate-limit-score-${batch}`, getRateLimitDelay('claude'))
    }
  }

  // Assemble final risk result
  const riskResult = {
    assessments: allAssessments,
    overallRiskScore: lastRiskResult!.overallRiskScore,
    overallRiskLevel: lastRiskResult!.overallRiskLevel,
    executiveSummary: lastRiskResult!.executiveSummary,
    perspective: lastRiskResult!.perspective,
    riskDistribution: lastRiskResult!.riskDistribution,
  }
  ```

  **Note:** The executive summary and overall scores from `lastRiskResult` will only reflect the last batch's subset. This is a known tradeoff. The overall risk score gets recalculated via `calculateWeightedRisk` in the persist-final step anyway, and the executive summary was already being populated in the scoring loop. For accuracy of the executive summary across all clauses, we can generate it separately after all batches complete, or accept the last batch's summary as a reasonable approximation. Given that the risk scorer's executive summary considers the full set of clauses it receives, and the last batch only sees a subset, we should generate a final summary step.

  **Add a post-scoring summary step:**

  After the batch loop, add a step to generate the executive summary using all clauses and all assessments:

  ```typescript
  // Generate executive summary with full context (not just last batch)
  const riskSummary = await step.run('generate-risk-summary', () =>
    runRiskScorerAgent({
      clauses: clausesToScore,
      budgetTracker,
      perspective: 'balanced',
      summaryOnly: true, // If supported, otherwise accept the full re-run cost
    })
  )
  ```

  Actually, checking the risk scorer agent: it generates `executiveSummary` as part of its output. For batch processing, the most practical approach is to use `lastRiskResult`'s `executiveSummary` only if `clausesToScore.length <= SCORER_BATCH_SIZE` (single batch), otherwise run a final summary-only call. But since we don't have a `summaryOnly` mode, and the executive summary is already populated in the persist-final step from `riskResult.executiveSummary`, we can simply accept that the executive summary from the last batch is a partial view.

  **Simpler approach:** After all batches, recalculate `overallRiskScore` and `overallRiskLevel` from allAssessments (these are already recalculated via `calculateWeightedRisk` in persist-final). For the executive summary, we already have one from `lastRiskResult`. This is acceptable for MVP since the executive summary from any batch gives reasonable context.

  Remove the old single `step.run('risk-scorer-agent', ...)` and its emitProgress call.

  Apply the same pattern to `analyzeNdaAfterOcr`.

  **Also update the persist-classifications step** to use the new `classifierResult` variable (which is now assembled from batches, not a single call result). The structure should be identical since we pushed all raw classifications and clauses into arrays.

  Remove the old single-call `emitProgress('scoring', ...)` after the old risk scorer step.
  </action>
  <verify>Run `pnpm lint`. Grep for `score-batch-` to confirm per-batch step IDs. Verify no remaining `step.run('risk-scorer-agent'` (old monolithic step). Verify the persist-classifications step still works with the batched classifierResult.</verify>
  <done>Risk scorer runs as per-batch steps with "Scoring clause 7 of 15..." progress, each batch independently retriable, rate limits respected between batches, persist-final uses accumulated assessments.</done>
</task>

</tasks>

<verification>
1. `pnpm lint` passes
2. Grep for `classify-batch-` in analyze-nda.ts returns matches for both functions
3. Grep for `score-batch-` in analyze-nda.ts returns matches for both functions
4. No remaining `step.run('classifier-agent'` or `step.run('risk-scorer-agent'` patterns
5. emitProgress calls show clause-level messages with counts
</verification>

<success_criteria>
- Classifier uses per-batch steps: `classify-batch-0`, `classify-batch-1`, etc.
- Risk scorer uses per-batch steps: `score-batch-0`, `score-batch-1`, etc.
- Progress messages show "Classifying clause X of Y..." and "Scoring clause X of Y..."
- Rate limit sleeps between batches
- Both analyzeNda and analyzeNdaAfterOcr updated consistently
</success_criteria>

<output>
After completion, create `.planning/phases/09-pipeline-orchestration/09-03-SUMMARY.md`
</output>
