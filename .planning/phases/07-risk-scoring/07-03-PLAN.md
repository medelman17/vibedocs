---
phase: 07-risk-scoring
plan: 03
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - inngest/functions/analyze-nda.ts
  - db/queries/risk-scoring.ts
autonomous: true

must_haves:
  truths:
    - "User can see a risk level for each clause in the analysis results"
    - "User sees a weighted overall risk score that accounts for clause category importance"
    - "User sees an executive summary highlighting top risk findings"
    - "User can identify the perspective used for the analysis"
    - "User sees a breakdown of how many clauses fall into each risk level"
  artifacts:
    - path: "db/queries/risk-scoring.ts"
      provides: "Risk scoring persistence and weighted scoring queries"
      contains: "persistRiskAssessments"
    - path: "inngest/functions/analyze-nda.ts"
      provides: "Pipeline integration: persist risk results + update analysis record"
      contains: "persist-risk-assessments"
  key_links:
    - from: "inngest/functions/analyze-nda.ts"
      to: "db/queries/risk-scoring.ts"
      via: "import persistRiskAssessments, calculateWeightedRisk"
      pattern: "persistRiskAssessments|calculateWeightedRisk"
    - from: "db/queries/risk-scoring.ts"
      to: "db/schema/analyses.ts"
      via: "import clauseExtractions, analyses"
      pattern: "clauseExtractions|analyses"
    - from: "db/queries/risk-scoring.ts"
      to: "db/schema/reference.ts"
      via: "import cuadCategories"
      pattern: "cuadCategories"
---

<objective>
Wire risk scoring results into the database: persist per-clause assessments to clauseExtractions, compute weighted document-level scores, and store executive summary.

Purpose: Without persistence, risk assessments are computed but lost. This plan closes the gap between agent output and queryable data.
Output: New `db/queries/risk-scoring.ts` with persistence/scoring queries, updated pipeline to persist results.
</objective>

<execution_context>
@/Users/medelman/.claude/get-shit-done/workflows/execute-plan.md
@/Users/medelman/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-risk-scoring/07-CONTEXT.md
@.planning/phases/07-risk-scoring/07-RESEARCH.md
@.planning/phases/07-risk-scoring/07-01-SUMMARY.md
@inngest/functions/analyze-nda.ts
@db/schema/analyses.ts
@db/schema/reference.ts
@db/queries/similarity.ts
@agents/risk-scorer.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create risk scoring queries module</name>
  <files>db/queries/risk-scoring.ts</files>
  <action>
Create `db/queries/risk-scoring.ts` with the following functions. Import directly from `@/db/client` (not through a barrel) per CLAUDE.md conventions.

1. `persistRiskAssessments(dbClient, tenantId, analysisId, documentId, assessments, perspective)`:
   - Takes the db client, tenant context, and array of `RiskAssessmentResult` from the agent
   - Maps each assessment to a `clauseExtractions` insert value:
     ```typescript
     {
       tenantId,
       analysisId,
       documentId,
       chunkId: assessment.clauseId,
       category: assessment.clause.category,
       secondaryCategories: assessment.clause.secondaryCategories ?? [],
       clauseText: assessment.clause.clauseText,
       startPosition: assessment.startPosition,
       endPosition: assessment.endPosition,
       confidence: assessment.clause.confidence,
       riskLevel: assessment.riskLevel,
       riskExplanation: assessment.explanation,
       evidence: {
         citations: assessment.evidence.citations,
         references: assessment.evidence.references,
         baselineComparison: assessment.evidence.baselineComparison,
       },
       metadata: {
         perspective,
         riskConfidence: assessment.confidence,
         atypicalLanguage: assessment.atypicalLanguage,
         atypicalLanguageNote: assessment.atypicalLanguageNote,
         negotiationSuggestion: assessment.negotiationSuggestion,
       },
     }
     ```
   - Batch insert in groups of 100
   - Use `onConflictDoUpdate` targeting the unique constraint `(analysisId, chunkId)`:
     - Update: `riskLevel`, `riskExplanation`, `evidence`, `metadata`, `updatedAt`
     - This supports re-scoring (same analysis, new perspective overwrites)
   - Return the count of persisted records

2. `calculateWeightedRisk(dbClient, assessments)`:
   - Query `cuadCategories` table for `name` and `riskWeight`
   - Build a weight map: `Map<string, number>` from category name to weight (default 1.0)
   - Apply risk value mapping: aggressive=1.0, cautious=0.5, standard=0.0, unknown=0.25
   - Compute weighted score: `sum(riskValue * categoryWeight) / sum(categoryWeight) * 100`
   - Round to integer
   - Determine level: score >= 60 = 'aggressive', >= 30 = 'cautious', else 'standard'
   - Return `{ score: number, level: RiskLevel }`
   - If no categories in DB (bootstrap not run), fall back to the existing uniform weighting logic

3. `updateAnalysisWithRiskResults(dbClient, analysisId, riskOutput)`:
   - Updates the `analyses` record with:
     - `overallRiskScore`: from weighted calculation
     - `overallRiskLevel`: from weighted calculation
     - `summary`: executive summary string
     - `metadata`: merge existing metadata with `{ perspective, riskDistribution }`
   - Uses `sql` for JSONB merge: `jsonb_set` or spread with existing

Import types from `@/agents/risk-scorer` for `RiskAssessmentResult` and `RiskScorerOutput`.
Import schema from `@/db/schema/analyses` (clauseExtractions, analyses) and `@/db/schema/reference` (cuadCategories).
Import `eq, sql` from `drizzle-orm`.
  </action>
  <verify>
    - `pnpm build` succeeds
    - File exists at `db/queries/risk-scoring.ts`
    - Exports `persistRiskAssessments`, `calculateWeightedRisk`, `updateAnalysisWithRiskResults`
    - Verify query functions compile by importing them in a test script: `import { persistRiskAssessments, calculateWeightedRisk } from '@/db/queries/risk-scoring'` and confirming no type errors
    - Verify `calculateWeightedRisk` handles edge cases: empty assessments array returns `{ score: 0, level: 'standard' }`, missing cuadCategories fallback to uniform weights
  </verify>
  <done>
    - Risk assessment persistence with upsert (supports re-scoring)
    - Weighted document-level scoring using cuadCategories.riskWeight
    - Analysis update function for risk results, summary, and perspective
    - Query functions handle edge cases: empty assessments, missing cuadCategories table data
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire persistence into Inngest pipeline</name>
  <files>inngest/functions/analyze-nda.ts</files>
  <action>
Modify `inngest/functions/analyze-nda.ts` to persist risk scoring results. Apply changes to BOTH `analyzeNda` and `analyzeNdaAfterOcr` functions:

**IMPORTANT (context_compliance):** Ensure the risk scorer agent call explicitly passes `perspective: 'balanced'` as the default. The user decision locks the default perspective as balanced/neutral. While the agent may default to balanced internally, the pipeline must be explicit to honor this decision and make the perspective visible in the persisted metadata. Update the existing `runRiskScorerAgent` call to:
```typescript
const riskResult = await step.run('risk-scorer-agent', () =>
  runRiskScorerAgent({
    clauses: classifiedClauses,
    budgetTracker,
    perspective: 'balanced', // Default perspective per user decision
  })
)
```

1. Add imports at the top:
```typescript
import {
  persistRiskAssessments,
  calculateWeightedRisk,
  updateAnalysisWithRiskResults,
} from '@/db/queries/risk-scoring'
```

2. After the `risk-scorer-agent` step and its `emitProgress` call, add a new step to persist risk assessments:
```typescript
// Step: Persist per-clause risk assessments to clauseExtractions
await step.run('persist-risk-assessments', async () => {
  await persistRiskAssessments(
    ctx.db,
    tenantId,
    analysisId,
    documentId,
    riskResult.assessments,
    riskResult.perspective,
  )
})
```

3. In the `persist-final` step, replace the direct risk score assignment with the weighted calculation:
```typescript
await step.run('persist-final', async () => {
  const usage = budgetTracker.getUsage()

  // Calculate weighted risk score using category importance from cuadCategories
  const weightedRisk = await calculateWeightedRisk(ctx.db, riskResult.assessments)

  await ctx.db
    .update(analyses)
    .set({
      status: 'completed',
      overallRiskScore: weightedRisk.score,
      overallRiskLevel: weightedRisk.level,
      summary: riskResult.executiveSummary,
      gapAnalysis: gapResult.gapAnalysis,
      tokenUsage: usage,
      actualTokens: usage.total.total,
      estimatedCost: usage.total.estimatedCost,
      processingTimeMs: Date.now() - startTime,
      completedAt: new Date(),
      metadata: sql`COALESCE(metadata, '{}'::jsonb) || ${JSON.stringify({
        perspective: riskResult.perspective,
        riskDistribution: riskResult.riskDistribution,
      })}::jsonb`,
    })
    .where(eq(analyses.id, analysisId))
})
```

Note: Use `sql` template literal for JSONB merge to preserve existing metadata (like truncation warnings, error codes) while adding perspective and riskDistribution.

4. Also update the completion event data to include `summary`:
```typescript
await step.sendEvent('analysis-completed', {
  name: 'nda/analysis.completed',
  data: {
    documentId,
    analysisId,
    tenantId,
    overallRiskScore: weightedRisk.score,  // Use weighted score
    overallRiskLevel: weightedRisk.level,  // Use weighted level
  },
})
```

Important: The `weightedRisk` variable is computed inside `persist-final` step, so the completion event also needs to be inside or after that step. If the existing structure has the event send AFTER persist-final, reference the weighted values. You may need to move the weighted risk calculation outside the persist-final step into its own step so the values are available, OR compute it inside persist-final and use `riskResult.overallRiskScore` for the event (since the event is for real-time consumers who don't need exact weighted scores).

Simplest approach: keep the completion event using `riskResult.overallRiskScore/Level` since it's for real-time notification only, while the DB gets the weighted version. The UI reads from DB.
  </action>
  <verify>
    - `pnpm build` succeeds
    - `pnpm lint` passes
    - Both `analyzeNda` and `analyzeNdaAfterOcr` include `persist-risk-assessments` step
    - Both functions use `calculateWeightedRisk` in persist-final
    - Executive summary stored in `analyses.summary`
  </verify>
  <done>
    - Pipeline explicitly passes `perspective: 'balanced'` as default to risk scorer agent
    - Per-clause risk assessments persisted to clauseExtractions after risk scorer runs
    - Weighted document-level score computed using cuadCategories.riskWeight
    - Executive summary stored in analyses.summary column
    - Perspective and risk distribution stored in analyses.metadata
    - Both main and post-OCR pipeline updated identically
  </done>
</task>

</tasks>

<verification>
- `pnpm build` succeeds
- `pnpm lint` passes
- `db/queries/risk-scoring.ts` exports persistence and weighted scoring functions
- Pipeline persists per-clause risk results after scoring step
- Weighted scoring uses cuadCategories.riskWeight from database
- Executive summary populates analyses.summary
</verification>

<success_criteria>
- Risk assessments persist to clauseExtractions (previously empty riskLevel/riskExplanation/evidence columns)
- Document-level score uses importance-weighted calculation
- Executive summary and perspective metadata stored on analysis record
- Both pipeline variants (main + post-OCR) updated
</success_criteria>

<output>
After completion, create `.planning/phases/07-risk-scoring/07-03-SUMMARY.md`
</output>
